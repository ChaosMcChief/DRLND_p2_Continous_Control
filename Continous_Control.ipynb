{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Continous control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we start and interact with the environment to train agents or watch them control a multi-joint robotic arm.\n",
    "\n",
    "### 1. Necessary imports and defining the constants\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from unityagents import UnityEnvironment\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ddpg_agent_orig import Agent\n",
    "import Config\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Initialize the config in which all hyperparams are stored\n",
    "config = Config.config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define all the constants relevant to this notebook. This is the only cell you need to modify. The rest of the notebook should run without any modifications.\n",
    "Change the `env_file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_file_name = 'Reacher_Windows_x86_64_twenty/Reacher.exe' # Path to the Unity environment.\n",
    "per = True                                                  # Priotirized experience replay buffer\n",
    "n_episodes = 400                                            # Number of episodes to train on\n",
    "n_episodes_to_watch = 1                                     # Numbers of episodes to watch the trained agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we start the environment, save the `brain_name`, which we need to interact with the environment and save the size of the state- and action-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_file_name)\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "\n",
    "# dimension of the state-space \n",
    "num_agents = env_info.vector_observations.shape[0]\n",
    "state_size = env_info.vector_observations.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train an agent\n",
    "\n",
    "In the next code cells we define a training-method and anfter that initialize and train agents. The trained model-parameters will be saved every 250 episodes in `checkpoint_{model_suff}.pth`. It loops through all specified agent-parameters. If `per==True` it will prepopulate the memory with experiences from random actions before training.\n",
    "\n",
    "Training will be done on the gpu if one is available.\n",
    "\n",
    "If you just want to analyse already trained agent, you can skip this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepop_memory(agent, env, action_size):\n",
    "    \"\"\" Prepoulates the memory with experiences \n",
    "    from random actions if training with prioritized experience replay.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        agent (Agent): instance of class Agent which memory should be filled.\n",
    "        env (reacher environment): environment to interact with.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print(\"Prepopulating Memory...\")\n",
    "    pretrain_length = agent.memory.tree.capacity \n",
    "    \n",
    "    actions = 2*np.random.rand(pretrain_length//agent.num_agents, agent.num_agents, action_size) - 1\n",
    "    \n",
    "    env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "    state = env_info.vector_observations\n",
    "\n",
    "    for i in tqdm(range(actions.shape[0])):\n",
    "               \n",
    "        # Random action\n",
    "        action = actions[i]\n",
    "        \n",
    "        # Take the action\n",
    "        env_info = env.step(action)[brain_name] \n",
    "\n",
    "        # Get next_state, reward and done\n",
    "        next_state = env_info.vector_observations   # get the next state\n",
    "        reward = env_info.rewards                   # get the reward\n",
    "        done = env_info.local_done                  # see if episode has finished\n",
    "\n",
    "        # Store the experiences in the memory\n",
    "        # Save experience of each agent in replay memory\n",
    "        for i in range(agent.num_agents):\n",
    "            agent.memory.add(state[i,:], action[i,:], reward[i], next_state[i,:], done[i])\n",
    "\n",
    "        #agent.memory.add(state, action, reward, next_state, done)\n",
    "               \n",
    "        # Reset env if done\n",
    "        if done:\n",
    "            env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "            state = env_info.vector_observations\n",
    "        else:\n",
    "            state = next_state\n",
    "    pickle.dump(agent.memory,open('agent_memory_per_init.pkl','wb'))\n",
    "    return agent\n",
    "\n",
    "def train_agent(n_episodes=2000, model_suff=\"\"):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        model_suff (str): string wich will be appended to the saved model-parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    \n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations\n",
    "        score = np.zeros(agent.num_agents)\n",
    "\n",
    "        # Decay the action-noise and reset randomer\n",
    "        agent.decay_epsilon()\n",
    "        agent.reset()\n",
    "\n",
    "        while True:\n",
    "            \n",
    "            action = agent.act(state)\n",
    "            env_info = env.step(action)[brain_name]         # send the action to the environment\n",
    "            next_state = env_info.vector_observations       # get the next state\n",
    "            reward = env_info.rewards                       # get the reward\n",
    "            done = env_info.local_done                      # see if episode has finished\n",
    "            \n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += np.array(reward)\n",
    "           \n",
    "            if np.any(done): \n",
    "                break \n",
    "\n",
    "        scores_window.append(np.mean(score))       # save most recent score\n",
    "        scores.append(np.mean(score))              # save most recent score\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tLast Score: {:.2f}'.format(i_episode, np.mean(scores_window), scores[-1]), end=\"\")\n",
    "        if i_episode % 10 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            torch.save(agent.critic.state_dict(), f\"checkpoint_critic_episode_{model_suff}.pth\")\n",
    "            torch.save(agent.actor.state_dict(), f\"checkpoint_actor_episode_{model_suff}.pth\")\n",
    "            pickle.dump(scores, open(f\"Scores_interrim_{model_suff}.pkl\", 'wb'))\n",
    "        if (np.array(scores_window)>=30).all() or (i_episode>=n_episodes+1):\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            torch.save(agent.critic.state_dict(), f\"checkpoint_critic_episode_final_{model_suff}.pth\")\n",
    "            torch.save(agent.actor.state_dict(), f\"checkpoint_actor_episode_final_{model_suff}.pth\")\n",
    "            pickle.dump(scores, open(f\"Scores_final_{model_suff}.pkl\", 'wb'))\n",
    "            break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent woper is now training...\n",
      "Prepopulating the Memory..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███▊                              | 11185/100000 [00:34<04:38, 318.52it/s]"
     ]
    }
   ],
   "source": [
    "# Create the Agent and let it train\n",
    "agent = Agent(config=config, \n",
    "                state_size=state_size, \n",
    "                action_size=action_size, \n",
    "                num_agents=num_agents, \n",
    "                seed=0, per=per)\n",
    "if per: agent = prepop_memory(agent, env)\n",
    "\n",
    "# Train the agent and save the scores for later analysis\n",
    "scores = train_agent(n_episodes=n_episodes, model_suff=suff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Whatch trained agents\n",
    "Next we can watch a trained agent control 20 robotic arms for `n_episodes_to_watch` episodes. Therefore we load the model-parameters, reset the environment and loop through the specified number of episodes only using the calculated actions without any random noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score: 29.5\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(config=config, \n",
    "                state_size=state_size, \n",
    "                action_size=action_size, \n",
    "                num_agents=num_agents, \n",
    "                seed=0, per=per)\n",
    "agent.actor.load_state_dict(torch.load(\"checkpoint_actor_episode_wper.pth\", map_location=agent.config.device))\n",
    "agent.critic.load_state_dict(torch.load(\"checkpoint_critic_episode_wper.pth\", map_location=agent.config.device))\n",
    "agent.is_training = False\n",
    "\n",
    "scores = []                            # list containing scores from each episode\n",
    "for i_episode in range(1, n_episodes_to_watch+1):    # Loop through five episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "    state = env_info.vector_observations\n",
    "    score = np.zeros(num_agents)\n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        state = env_info.vector_observations             # get the next state\n",
    "        reward = env_info.rewards                        # get the reward\n",
    "        done = env_info.local_done                       # see if episode has finished\n",
    "\n",
    "        score += reward                                     # update the score\n",
    "\n",
    "        if np.any(done):\n",
    "            break \n",
    "    scores.append(np.mean(score))              # save most recent score\n",
    "print(f\"Avg. score: {np.mean(scores):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Plot the learning-curve\n",
    "In the last section we want to take a look at the learning curve. For orientation the goal-score (30) is also plottet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Score')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_scores = pickle.load(open(\"Scores_interrim_wper.pkl\", 'rb'))\n",
    "plt.plot(range(1,len(training_scores)+1), training_scores, 'b')\n",
    "plt.plot(np.ones(len(training_scores))*30, 'k--')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Close the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
